{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Periscope + Sagemaker\n",
    "Hello! Welcome to Periscope + Sagemaker!\n",
    "\n",
    "## Introduction\n",
    "In this demo, we will be using the XGBoost library on Sagemaker to predict the lifetime revenue of Toto customers. If you are new to Jupyter notebooks, just press the Run button at the top to run a code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "Let's start by specifying:\n",
    "\n",
    "* The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "\n",
    "* The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s).\n",
    "\n",
    "**Note:** This notebook was created and tested on an ml.t2.medium notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket='sagemaker-periscopedata-demo-nyc'\n",
    "data_key = 'enhancedtotodataset.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "# set prefix for this instance\n",
    "# please input your name in the following set of square brackets, making sure to use appropriate directory characters\n",
    "prefix = 'sagemaker/[your-name-here]-xgboost-batch-dm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import the Python libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "Because Periscope has already brought the data into S3 as a CSV, importing it into a dataframe requires only a single line of Python. Here we bring the data in from S3 to a pandas dataframe and confirm the information by printing the top 5 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv from S3\n",
    "df = pd.read_csv(data_location)\n",
    "\n",
    "# display the first 5 records to verify the import\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Most of the data preparation and feature engineering has already been performed in Periscope Data. There is one final step that is best done in Python: one-hot encoding the categorical variables. After importing the data from Periscope, this is the last step needed before running the training data through an ML model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the categorical variables are currently encoded as numeric. The number of categories is low and can easily be one-hot encoded using get_dummy()\n",
    "\n",
    "# categorical columns = max_dog_size, min_dog_size, requester_gender, provider_gender, experience\n",
    "# continuous = walk_count, dog_count, requester_fee, previous_client_count, price_per_walk, provider_fee, percent_morning_walks, percent_afternoon_walks, percent_evening_walks\n",
    "df = pd.get_dummies(df, columns = [\"max_dog_size\", \"min_dog_size\", \"requester_gender\", \"provider_gender\", \"experience\"])\n",
    "\n",
    "#verify that the one-hot encoding (creation of boolean for each categorical variable) succeeded\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models\n",
    "\n",
    "The most common way of preventing overfitting is to build models with the concept that a model shouldn't only be judged on its fit to the data it was trained on, but also on \"new\" data. There are several different ways of operationalizing this, holdout validation, cross-validation, leave-one-out validation, etc. For our purposes, we'll simply randomly split the data into 3 uneven groups. The model will be trained on 70% of data, it will then be evaluated on 20% of data to give us an estimate of the accuracy we hope to have on \"new\" data, and 10% will be held back as a final testing dataset which will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=1729), [int(0.7 * len(df)), int(0.9 * len(df))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker's XGBoost container expects data in the libSVM or CSV data format. For this example, we'll stick to CSV. Note that the first column must be the target variable and the CSV should not include headers. Also, notice that although repetitive it's easiest to do this after the train|validation|test split rather than before. This avoids any misalignment issues due to random reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_data['lifetime_revenue'], train_data.drop(['lifetime_revenue'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "pd.concat([validation_data['lifetime_revenue'], validation_data.drop(['lifetime_revenue'], axis=1)], axis=1).to_csv('validation.csv', index=False, header=False)\n",
    "test_data.drop(['lifetime_revenue'], axis=1).to_csv('test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll copy the files to S3 for Amazon SageMaker's managed training to pickup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "There are several intricacies to understanding the algorithm, but at a high level, gradient boosted trees works by combining predictions from many simple models, each of which tries to address the weaknesses of the previous models. By doing this the collection of simple models can actually outperform large, complex models. Other Amazon SageMaker notebooks elaborate on gradient boosting trees further and how they differ from similar algorithms.\n",
    "\n",
    "xgboost is an extremely popular, open-source package for gradient boosted trees. It is computationally powerful, fully featured, and has been successfully used in many machine learning competitions. Let's start with a simple xgboost model, trained using Amazon SageMaker's managed, distributed training framework.\n",
    "\n",
    "First we'll need to specify the ECR container location for Amazon SageMaker's implementation of XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest',\n",
    "              'ap-northeast-1': '501404015308.dkr.ecr.ap-northeast-1.amazonaws.com/xgboost:latest',\n",
    "              'ap-northeast-2': '306986355934.dkr.ecr.ap-northeast-2.amazonaws.com/xgboost:latest'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create s3_inputs that our training function can use as a pointer to the files in S3, which also specify that the content type is CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need to specify training parameters to the estimator. This includes:\n",
    "\n",
    "1. The xgboost algorithm container\n",
    "2. The IAM role to use\n",
    "3. Training instance type and count\n",
    "4. S3 location for output data\n",
    "5. Algorithm hyperparameters\n",
    "And then a .fit() function which specifies:\n",
    "\n",
    "1. S3 location for output data. In this case we have both a training and validation set which are passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='reg:linear', # use linear regression to create a continuous output\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting\n",
    "Now that we've trained the xgboost algorithm on our data, let's deploy a model that's hosted behind a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "There are many ways to compare the performance of a machine learning model, but let's start by simply comparing actual to predicted values.\n",
    "\n",
    "Let's use SageMaker's newly announced bulk inferencing functionality to make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "input_prefix = prefix + '/test'\n",
    "csv_file = 'test.csv'\n",
    "input_data = 's3://{}/{}'.format(bucket, input_prefix)\n",
    "output_prefix = prefix + '/xgboost-batch-test-output'\n",
    "output_data = 's3://{}/{}'.format(bucket, output_prefix)\n",
    "\n",
    "# Important\n",
    "# Update this value with the model name from the output of the hosting step\n",
    "model_name = 'xgboost-2018-07-17-09-08-32-655'\n",
    "job_name = model_name\n",
    "\n",
    "batch_job_name = 'xgboost-batch' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "batch = boto3.client('sagemaker')\n",
    "\n",
    "create_params = \\\n",
    "{\n",
    "    \"TransformJobName\": batch_job_name,\n",
    "    \"ModelName\": model_name, \n",
    "    \"MaxConcurrentTransforms\": 8,\n",
    "    \"BatchStrategy\": 'MultiRecord',\n",
    "\n",
    "    \"TransformInput\": {\n",
    "       \"ContentType\": \"text/csv\",\n",
    "       \"SplitType\": \"Line\",\n",
    "       \"CompressionType\": \"None\",\n",
    "       \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "               \"S3DataType\": \"S3Prefix\",\n",
    "               \"S3Uri\": input_data\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"TransformOutput\": {\n",
    "        \"S3OutputPath\": output_data,\n",
    "        \"AssembleWith\": \"Line\"\n",
    "    },\n",
    "    \"TransformResources\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m4.xlarge\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Job name is \" + job_name)\n",
    "batch.create_transform_job(**create_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for it to Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def describe(job_name):\n",
    "    b = batch.describe_transform_job(TransformJobName=job_name)\n",
    "    b.pop('ResponseMetadata')\n",
    "    return b\n",
    "\n",
    "def wait_for(job_name, sleep_time=30):\n",
    "    while True:\n",
    "        desc = describe(job_name)\n",
    "        print('Status: {}'.format(desc['TransformJobStatus']))\n",
    "        if desc['TransformJobStatus'] != 'InProgress':\n",
    "            break\n",
    "        time.sleep(sleep_time)\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import yaml\n",
    "\n",
    "desc = wait_for(batch_job_name)\n",
    "print()\n",
    "print(yaml.dump(desc, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the data \n",
    "\n",
    "The output is written to S3 and we can recover it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part_file = csv_file + '.out'\n",
    "boto3.resource('s3').Bucket(bucket).Object('{}/{}'.format(output_prefix,part_file)).download_file(part_file)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "predictions = pd.read_csv(part_file, header=None)\n",
    "predictions.columns = ['predictions']\n",
    "\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Predictions\n",
    "\n",
    "Let's use another method to make predictions on the training data so we can compare how the model fits the test data and the training data.\n",
    "\n",
    "First we'll need to determine how we pass data into and receive data from our endpoint. Our data is currently stored as NumPy arrays in memory of our notebook instance. To send it in an HTTP POST request, we'll serialize it as a CSV string and then decode the resulting CSV.\n",
    "\n",
    "_Note: For inference with CSV format, SageMaker XGBoost requires that the data does NOT include the target variable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "\n",
    "1. Loop over our test dataset\n",
    "2. Split it into mini-batches of rows\n",
    "3. Convert those mini-batches to CSV string payloads (notice, we drop the target variable from our dataset first)\n",
    "4. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "5. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "# export test predictions\n",
    "test_data_with_pred = test_data\n",
    "test_data_with_pred.insert(2, 'predictions', predictions)\n",
    "\n",
    "test_data_with_pred.head()\n",
    "test_data_with_pred.to_csv('toto_test_predictions.csv', index=False, header=True)\n",
    "\n",
    "# export train data with predictiona\n",
    "train_predictions = predict(train_data.drop(['lifetime_revenue'], axis=1).values)\n",
    "train_data_with_pred = train_data\n",
    "train_data_with_pred.insert(2, 'predictions', train_predictions)\n",
    "\n",
    "train_data_with_pred.head()\n",
    "train_data_with_pred.to_csv('toto_train_predictions.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE \n",
    "\n",
    "The root mean square error helps us understand the difference between our predictions and the actual lifetime revenue. It aggregates the error/residuals in a way and helps us better evaluate the performance of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, actuals):\n",
    "    rmse = ((predictions - actuals) ** 2).mean() ** .5\n",
    "    return rmse\n",
    "\n",
    "rmse(predictions = np.round(predictions['predictions']), actuals = test_data['lifetime_revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the RSME is $1932.86. Although this is a large number, it does make sense given the range of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Predictions\n",
    "\n",
    "Visualizing predictions is a helpful way to evaluate the efficacy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "max_lim = max(int(np.max(np.round(predictions['predictions']))), int(np.max(test_data['lifetime_revenue'])))\n",
    "x = np.linspace(0, max_lim, 10)\n",
    "plt.plot(x, x, linewidth = 2.5, linestyle = '-.', alpha = 0.5, label = 'Actual')\n",
    "\n",
    "#regression part\n",
    "sns.regplot(x=np.round(predictions['predictions']), y=test_data['lifetime_revenue'], color = 'purple', label = 'Prediction')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Predictive vs Actual Lifetime Revenue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that predictions are more accurate in the lower ranges from 0 to \\$150.00 since this is where we have the most data. For larger values and predictions, it becomes more difficult for the model to extrapolate. Looking at the graph, it appears that the model tends to overpredict for values over $150.00. Another graph that investigates this widening margin of error can be created with a simple linear regression model plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.residplot(x=np.round(predictions['predictions']), y=test_data['lifetime_revenue'], color = 'purple')\n",
    "plt.xlabel('LTV')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "This example analyzed a relatively small dataset, but utilized Amazon SageMaker features such as distributed, managed training and real-time model hosting, which could easily be applied to much larger problems. In order to improve predictive accuracy further, we could tweak value we threshold our predictions at to alter the mix of false-positives and false-negatives, or we could explore techniques like hyperparameter tuning. In a real-world scenario, we would also spend more time engineering features by hand and would likely look for additional datasets to include which contain additional information not available in our initial dataset.\n",
    "\n",
    "### Clean-up\n",
    "If you are done with this notebook, please run the cell below. This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
